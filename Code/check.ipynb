{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31929566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id           title                                               text  \\\n",
      "0   0  Deaths in 2022  The following notable deaths occurred in 2022....   \n",
      "1   1         YouTube  YouTube is a global online video sharing and s...   \n",
      "2   2         YouTube  In October 2006, YouTube was bought by Google ...   \n",
      "3   3         YouTube  Since its purchase by Google, YouTube has expa...   \n",
      "4   4         YouTube  YouTube has had an unprecedented social impact...   \n",
      "\n",
      "                                            url   wiki_id        views  \\\n",
      "0  https://en.wikipedia.org/wiki?curid=69407798  69407798  5674.449219   \n",
      "1   https://en.wikipedia.org/wiki?curid=3524766   3524766  5409.561035   \n",
      "2   https://en.wikipedia.org/wiki?curid=3524766   3524766  5409.561035   \n",
      "3   https://en.wikipedia.org/wiki?curid=3524766   3524766  5409.561035   \n",
      "4   https://en.wikipedia.org/wiki?curid=3524766   3524766  5409.561035   \n",
      "\n",
      "   paragraph_id  langs                                                emb  \n",
      "0             0     38  [0.009267602, 0.009592271, 0.025238374, 0.0134...  \n",
      "1             0    184  [0.03334248, -0.1543947, 0.0031653661, -0.0331...  \n",
      "2             1    184  [-0.06815702, -0.1281427, 0.015541038, 0.00125...  \n",
      "3             2    184  [-0.018927645, -0.18486351, -0.014122988, -0.0...  \n",
      "4             3    184  [-0.026521929, -0.00996005, -0.009151534, -0.0...  \n"
     ]
    }
   ],
   "source": [
    "# inspect D:\\Life\\Academic\\Skripsi\\Code\\data\\wikipediasmallLM\\data\\train-00000-of-00145-437d77a320cee9e2.parquet\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"D:\\\\Life\\\\Academic\\\\Skripsi\\\\Code\\\\data\\\\wikipediasmallLM\\\\data\\\\train-00000-of-00145-437d77a320cee9e2.parquet\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a6e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all emb to list\n",
    "df[\"emb\"] = df[\"emb\"].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9adf27ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].is_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56694b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a047d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=1455228)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "COLLECTION_NAME = \"wikipedia\"\n",
    "\n",
    "client.count(COLLECTION_NAME, exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f6746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=1455228 points_count=1455228 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=True, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=8, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=True, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=10000, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=4), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=0.95, always_ram=False)), strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab0eebe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2419d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"wikipedia\"\n",
    "BATCH_SIZE = 128\n",
    "PROGRESS_FILE = \"progress.json\"\n",
    "VECTOR_SIZE = 384\n",
    "DATA_DIR = r\"D:\\Life\\Academic\\Skripsi\\Code\\data\\wikipediasmallLM\\data\"\n",
    "NUM_FILES_TO_PROCESS = 1  # Number of files to process (set to None for all files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b003b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import (\n",
    "    VectorParams,\n",
    "    Distance,\n",
    "    HnswConfigDiff,\n",
    "    ScalarQuantization,\n",
    "    ScalarQuantizationConfig,\n",
    "    ScalarType\n",
    ")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE,\n",
    "        distance=Distance.COSINE,\n",
    "        on_disk=True\n",
    "    ),\n",
    "    hnsw_config=HnswConfigDiff(\n",
    "        m=8,\n",
    "        ef_construct=50,\n",
    "        on_disk=True\n",
    "    ),\n",
    "    optimizers_config=models.OptimizersConfigDiff(\n",
    "        memmap_threshold=10000,\n",
    "        indexing_threshold=20000\n",
    "    ),\n",
    "    quantization_config=ScalarQuantization(\n",
    "        scalar=ScalarQuantizationConfig(\n",
    "            type=ScalarType.INT8,\n",
    "            quantile=0.999,\n",
    "            always_ram=False\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e430fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "try:\n",
    "    with open(PROGRESS_FILE, \"r\") as f:\n",
    "        progress_data = json.load(f)\n",
    "    # Initialize last_file_index if not present\n",
    "    if \"last_file_index\" not in progress_data:\n",
    "        progress_data[\"last_file_index\"] = -1\n",
    "except FileNotFoundError:\n",
    "    progress_data = {\"last_file_index\": -1, \"file_progress\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48ce4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 parquet files.\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.parquet\")))\n",
    "print(f\"Found {len(files)} parquet files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5cac60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = progress_data[\"last_file_index\"] + 1\n",
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "240bca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_FILES_TO_PROCESS is None:\n",
    "    end_index = len(files)  # Process all remaining files\n",
    "else:\n",
    "    end_index = min(start_index + NUM_FILES_TO_PROCESS, len(files))\n",
    "\n",
    "if start_index >= end_index:\n",
    "    print(\"All files already processed. Nothing to do.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c924a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Life\\\\Academic\\\\Skripsi\\\\Code\\\\data\\\\wikipediasmallLM\\\\data\\\\train-00000-of-00145-437d77a320cee9e2.parquet']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_process = files[start_index:end_index]\n",
    "files_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db81238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files 0 to 0 (1 files)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing files {start_index} to {end_index-1} ({len(files_to_process)} files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dbd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
